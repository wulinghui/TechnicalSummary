---
title: 分布式日志追踪系统
date: 2022-03-14 16:35:33
permalink: /pages/98c2f0/
categories:
  - 项目
tags:
  - 
author: 
  name: wulinghui
  link: https://gitee.com/hellowllh/projects
---
# 需求场景

- 分析MQ服务器日志，定位问题
- 采集Tomcat、nginx服务器日志信息
- APM系统中的日志模块。

# 整体流程图

FileBeat 采集 ： Beats可以直接将数据发送到Elasticsearch或者发送到Logstash，

Logstash  过滤和格式化处理 ： 基于Logstash（非常吃内存，但是功能更加丰富）可以进一步地对数据进行处理，

ES供搜索 : 然后将处理后的数据存入到Elasticsearch

Kibana供可视化分析 : 最后使用Kibana进行数据可视化。 

# Beats

Beats是一个开放源代码的数据发送器。我们可以把Beats作为一种代理安装在我们的服务器上，用于发送数据。

## 类型

| 审计数据        | AuditBeat    |
| --------------- | ------------ |
| 日志文件        | FileBeat     |
| 云数据          | FunctionBeat |
| 可用性数据      | HeartBeat    |
| 系统日志        | JournalBeat  |
| 指标数据        | MetricBeat   |
| 网络流量数据    | PacketBeat   |
| Windows事件日志 | Winlogbeat   |

## FileBeat

FileBeat专门用于转发和收集日志等文件数据的轻量级采集工具。

### 工作原理

- 启动FileBeat时，会启动一个或者多个输入（Input），这些Input监控指定的日志数据位置。
- FileBeat会针对每一个文件启动一个Harvester（收割机）
- Harvester读取每一个文件的日志，将新的日志发送到libbeat，libbeat将数据收集到一起，并将数据发送给后台Spooler做输出（Output）
- 输出到其他的中间件中、如Elasticsearch、Logstash、Kafka、Redis等等。
- **input** : 是负责管理Harvesters和查找所有要读取的文件的组件
- **Harvesters** : Harvesters负责读取单个文件的内容，它负责打开/关闭文件，并逐行读取每个文件的内容，将读取到的内容发送给输出
- 如何保持文件状态?? : 保存每个文件的状态，并定时将状态信息保存在磁盘的「注册表」文件中，保存读取的最后一次偏移量。
- 断点续传功能 ： 输出无法访问，FileBeat会记录成功发送的最后一行，并在输出（Elasticsearch或者Logstash）可用时，继续读取文件发送数据。

### 配置文件

- type :  log、stdin
- paths : 日志文件路径
- multiline.pattern : 匹配一行日志，是否需要采集。
- match：after 或 before，合并到上一行的末尾或开头
- negate：true 或 false；默认是false，匹配pattern的行合并到上一行；true，不匹配pattern的行合并到上一行
- output.***  ： 可以是redis、es等等
- hosts ： 输出的地址







# Logstash

它可以动态地将不同来源的数据统一采集，并按照指定的数据格式进行处理后，将数据加载到其他的目的地。

最开始，Logstash主要是针对日志采集，但后来Logstash开发了大量丰富的**插件**，所以，它可以做更多的海量数据的采集。

他的输入有很多web log、log4j、Beats、系统、网络、防火墙的日志等等。

他的输出也很多: 关系型数据库、NoSQL数据库、MQ等等

通过下面的插件可以看过它更多的定位在于对数据过滤、转化处理。

## 对比FileBeat

logstash是jvm跑的，资源消耗比较大

而FileBeat是基于golang编写的，功能较少但资源消耗也比较小，更轻量级

logstash 具有filter功能，能过滤分析日志

logstash 和filebeat都具有日志收集功能，Filebeat更轻量，占用资源更少

logstash 具有**强大**的filter功能，能过滤分析日志

## [Logstash过滤器](https://www.elastic.co/guide/en/logstash/7.6/filter-plugins.html)

查看Logstash已经安装的插件 `cd /usr/local/es/logstash-7.6.1/`

### [Grok插件](https://cloud.tencent.com/developer/article/1651643)

是一种将非结构化日志解析为结构化的插件。这个工具非常适合用来解析系统日志、Web服务器日志、MySQL或者是任意其他的日志格式。

Grok是通过模式匹配的方式来识别日志中的数据,可以把Grok插件简单理解为升级版本的正则表达式。



### [Grok语法](https://github.com/logstash-plugins/logstash-patterns-core/blob/master/patterns/grok-patterns)

它拥有更多的模式，默认，Logstash拥有120个模式。如果这些模式不满足我们解析日志的需求，我们可以直接使用正则表达式来进行匹配。

grok模式的语法是：%{SYNTAX:SEMANTIC} ， SYNTAX指的是Grok模式名称，SEMANTIC是给模式匹配到的文本字段名。

默认在Grok中，所有匹配到的的数据类型都是字符串，如果要转换成int类型（目前只支持int和float），可以这样：%{NUMBER:duration:int} %{IP:client}

常用的Grok模式 ： 

| NUMBER | 匹配数字（包含：小数） |
| ------ | ---------------------- |
| INT    | 匹配整形数字           |
| POSINT | 匹配正整数             |
| WORD   | 匹配单词               |
| DATA   | 匹配所有字符           |
| IP     | 匹配IP地址             |
| PATH   | 匹配路径               |

### Grok调式

在Kibana中调式Grok

### [mutate插件](https://www.elastic.co/guide/en/logstash/7.6/plugins-filters-mutate.html)

mutate插件主要是作用在字段上，可以对字段做重命名、添加、删除、替换、修改结构

### [Date插件](https://www.elastic.co/guide/en/logstash/7.6/plugins-filters-date.html)

该插件专门用来解析字段中的日期。

默认字段经过date插件处理后，会输出到@timestamp字段，所以，我们可以通过修改target属性来重新定义输出字段。





# Elasticsearch



# Kibana

输入trace id 可以找到对应的日志内容。

# Skywalking

整合 Skywalking 和 ELK 后，通过 trace id，在 Skywaling 中快速看到链路中哪个环节出了问题，然后在 ELK 中按 trace id 搜索对应的系
统日志，这样就可以很方便的定位出问题，为线上排障提供了方便。 

简单地说就是把各个系统的日志通过trace id做了聚合，方便查看日志，不用再去每台服务器上去看了。



1. 搭建Skywalking OAP服务
2. 各个微服务配置Skywalking Agent
3. 集成日志框架，[生成traceId](https://github.com/apache/skywalking/blob/master/docs/en/setup/service-agent/java-agent/Application-toolkit-logback-1.x.md)
4. 开始整合ELK
5. 启动FileBeats收集本地日志
6. Logstash 解析 Trace ID
7. 在kibana中根据trace_id搜索对应的系统日志。
8. 看日志的定位问题，排查问题。





# 思考

- 为啥用FileBeat采集， Logstash 不是也可以吗???  

  > FileBeat小 快 有背压敏感协议，能保证稳定， Logstash 不行。 
  >
  > FileBeat和Logstash配合，实现背压机制。
  >
  > FileBeat做采集、Logstash做过滤和转化



# 参考资料

- [Flume、Logstash、Filebeat对比日志采集的不同](https://cloud.tencent.com/developer/article/1651643)

- [APM，监控界的扛把子，牛逼！](https://jishuin.proginn.com/p/763bfbd60ca7)

  >  Logs(日志) 、Traces(链路追踪) 和 Metrics(报表统计)

- [运维监控系统之Open-Falcon](https://www.cnblogs.com/nulige/p/7741580.html)
- [开源监控系统对比（Ganglia、Open-falcon、Prometheus、Zabbix)](https://cloud.tencent.com/developer/article/1639350)

