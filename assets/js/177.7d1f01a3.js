(window.webpackJsonp=window.webpackJsonp||[]).push([[177],{538:function(a,t,e){"use strict";e.r(t);var r=e(7),s=Object(r.a)({},(function(){var a=this,t=a._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[t("h1",{attrs:{id:"集群架构原理"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#集群架构原理"}},[a._v("#")]),a._v(" 集群架构原理")]),a._v(" "),t("h2",{attrs:{id:"节点类型"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#节点类型"}},[a._v("#")]),a._v(" 节点类型")]),a._v(" "),t("ul",[t("li",[a._v("Master主节点 ： 主资格节点的主要职责是和集群操作相关的内容")]),a._v(" "),t("li",[a._v("DataNode数据节点 ： 数据节点主要是存储索引数据的节点，主要对文档进行增删改查操作，聚合操作等。数据节点对cpu，内存，io要求较高， 在优化的时候需要监控数据节点的状态，当资源不够的时候，需要在集群中添加新的节点。")]),a._v(" "),t("li",[a._v("客户端节点: 当主节点和数据节点配置都设置为false的时候，该节点只能处理路由请求，处理搜索，分发索引操作等，从本质上来说该客户节点表现为智能负载平衡器。")])]),a._v(" "),t("blockquote",[t("p",[a._v("建议:")]),a._v(" "),t("p",[a._v("在一个生产集群中我们可以对这些节点的职责进行划分，建议集群中设置"),t("strong",[a._v("3台")]),a._v("以上的节点作为master节点，这些节点只负责成为主节点，维护整个集群的状态。再根据数据量设置一批data节点，这些节点只负责存储数据，后期提供建立索引和查询索引的服务，这样的话如果用户请求比较频繁，这些节点的压力也会比较大，所以在集群中建议再设置一批client节点(node.master: false node.data: false)，这些节点只负责处理用户请求，实现请求转发，负载均衡等功能")])]),a._v(" "),t("p",[a._v("节点状态，默认是主节点和数据节点，同时为true。")]),a._v(" "),t("h2",{attrs:{id:"健康状况"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#健康状况"}},[a._v("#")]),a._v(" 健康状况")]),a._v(" "),t("p",[a._v("green：每个索引的primary shard和replica shard都是active状态的")]),a._v(" "),t("p",[a._v("yellow：每个索引的primary shard都是active状态的，但是部分replica shard不是active状态，处于不可用的状态")]),a._v(" "),t("p",[a._v("red：不是所有索引的primary shard都是active状态的，部分索引有数据丢失了")]),a._v(" "),t("h2",{attrs:{id:"master节点"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#master节点"}},[a._v("#")]),a._v(" Master节点")]),a._v(" "),t("p",[a._v("在Elasticsearch启动时，会选举出来一个Master节点。当某个节点启动后，然后 使用Zen Discovery机制找到集群中的其他节点，并建立连接。并从候选主节点中选举出一个主节点。")]),a._v(" "),t("p",[a._v("一个Elasticsearch集群中，只有一个Master节点。在生产环境中，内存可以相对 小一点，但机器要稳定。")]),a._v(" "),t("p",[a._v("主要负责：")]),a._v(" "),t("ul",[t("li",[a._v("管理索引（创建索引、删除索引）")]),a._v(" "),t("li",[a._v("分配分片")]),a._v(" "),t("li",[a._v("维护元数据")]),a._v(" "),t("li",[a._v("管理集群节点状态")]),a._v(" "),t("li",[a._v("不负责数据写入和查询，比较轻量级")])]),a._v(" "),t("h2",{attrs:{id:"datanode节点"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#datanode节点"}},[a._v("#")]),a._v(" DataNode节点")]),a._v(" "),t("p",[a._v("在Elasticsearch集群中，会有N个DataNode节点。")]),a._v(" "),t("p",[a._v("大部分Elasticsearch的压力都在DataNode节点上，在生产环境中，内存最好配置大一些。")]),a._v(" "),t("p",[a._v("主要负责：")]),a._v(" "),t("ul",[t("li",[a._v("数据写入")]),a._v(" "),t("li",[a._v("数据检索")])]),a._v(" "),t("h2",{attrs:{id:"分片机制"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#分片机制"}},[a._v("#")]),a._v(" 分片机制")]),a._v(" "),t("p",[a._v("Elasticsearch是一个分布式的搜索引擎，索引的数据也是分成若干部分，分布在不同的服务器节点中，分布在不同服务器节点中的索引数据，就是分片。")]),a._v(" "),t("p",[a._v("一个索引（index）由多个shard（分片）组成，而分片是分布在不同的服务器上的。")]),a._v(" "),t("p",[a._v("Elasticsearch会自动管理分片，如果发现分片分布不均衡，就会自动迁移")]),a._v(" "),t("h2",{attrs:{id:"副本机制"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#副本机制"}},[a._v("#")]),a._v(" 副本机制")]),a._v(" "),t("p",[a._v("为了对Elasticsearch的分片进行容错，假设某个节点不可用，会导致整个索引库都将不可用。")]),a._v(" "),t("p",[a._v("对分片进行副本容错中，每一个分片，都会有对应的副本。")]),a._v(" "),t("p",[a._v("在Elasticsearch7.x以后，默认创建的索引为1个分片、每个分片有1个主分片和1个副本分片。")]),a._v(" "),t("h2",{attrs:{id:"指定分片、副本数量"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#指定分片、副本数量"}},[a._v("#")]),a._v(" 指定分片、副本数量")]),a._v(" "),t("p",[t("code",[a._v('"settings":{ "number_of_shards":3, "number_of_replicas":2 }')])]),a._v(" "),t("h2",{attrs:{id:"集群脑裂"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#集群脑裂"}},[a._v("#")]),a._v(" 集群脑裂")]),a._v(" "),t("p",[a._v("discovery.zen.minimum_master_nodes  设置为 master候选节点数量 / 2 + 1")]),a._v(" "),t("p",[a._v("为什么集群主节点要3台或以上，不能低于3台???  因为2台会出现脑列问题，导致数据丢失。1台单点故障。 2台一台挂了主节点就降级为node节点了。")]),a._v(" "),t("h1",{attrs:{id:"重要工作流程"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#重要工作流程"}},[a._v("#")]),a._v(" 重要工作流程")]),a._v(" "),t("h2",{attrs:{id:"写入原理"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#写入原理"}},[a._v("#")]),a._v(" 写入原理")]),a._v(" "),t("ol",[t("li",[a._v("选择任意一个DataNode发送请求，该节点就成为一个协调节点")]),a._v(" "),t("li",[a._v("计算得到文档要写入的分片")]),a._v(" "),t("li",[a._v("协调节点会进行路由，将请求转发给对应的primary shard所在的DataNode")]),a._v(" "),t("li",[a._v("节点上的Primary Shard处理请求，写入数据到索引库中，并将数据同步到Replica shard")]),a._v(" "),t("li",[a._v("Primary Shard和Replica Shard都保存好了文档，返回client。（分片和副本不在一个节点）")])]),a._v(" "),t("h2",{attrs:{id:"检索原理"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#检索原理"}},[a._v("#")]),a._v(" 检索原理")]),a._v(" "),t("ol",[t("li",[a._v("client发起查询请求，某个DataNode接收到请求，该DataNode就会成为协调节点")]),a._v(" "),t("li",[a._v("协调节点（Coordinating Node）将查询请求广播到每一个数据节点，这些数据节点的分片会处理该查询请求，每个分片进行数据查询，将符合条件的数据放在一个优先队列中，并将这些数据的文档ID、节点信息、分片信息返回给协调节点。")]),a._v(" "),t("li",[a._v("协调节点将所有的结果进行汇总，并进行全局排序")]),a._v(" "),t("li",[a._v("协调节点向包含这些文档ID的分片发送get请求，对应的分片将文档数据返回给协调节点，最后协调节点将数据返回给客户端")])]),a._v(" "),t("h2",{attrs:{id:"准实时索引实现"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#准实时索引实现"}},[a._v("#")]),a._v(" 准实时索引实现")]),a._v(" "),t("h3",{attrs:{id:"溢写到文件系统缓存"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#溢写到文件系统缓存"}},[a._v("#")]),a._v(" 溢写到文件系统缓存")]),a._v(" "),t("p",[a._v("当数据写入到ES分片时，会首先写入到内存中，然后通过内存的buffer生成一个segment，并刷到"),t("strong",[a._v("文件系统缓存")]),a._v("中，数据可以被检索（注意不是直接刷到磁盘）")]),a._v(" "),t("p",[a._v("ES中默认1秒，refresh一次")]),a._v(" "),t("h3",{attrs:{id:"写translog保障容错"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#写translog保障容错"}},[a._v("#")]),a._v(" 写translog保障容错")]),a._v(" "),t("p",[a._v("在写入到内存中的同时，也会记录translog日志，他属于硬盘级别，在refresh期间出现异常，会根据translog来进行数据恢复")]),a._v(" "),t("p",[a._v("等到文件系统缓存中的segment数据都刷到磁盘中，清空translog文件")]),a._v(" "),t("h3",{attrs:{id:"flush到磁盘"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#flush到磁盘"}},[a._v("#")]),a._v(" flush到磁盘")]),a._v(" "),t("p",[a._v("ES默认每隔30分钟会将文件系统缓存的数据刷入到磁盘")]),a._v(" "),t("h3",{attrs:{id:"segment合并"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#segment合并"}},[a._v("#")]),a._v(" segment合并")]),a._v(" "),t("p",[a._v("Segment太多时，ES定期会将多个segment合并成为大的segment，减少索引查询时IO开销，此阶段ES会真正的物理删除（之前执行过的delete的数据）")]),a._v(" "),t("h1",{attrs:{id:"分值计算底层原理"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#分值计算底层原理"}},[a._v("#")]),a._v(" 分值计算底层原理")]),a._v(" "),t("h2",{attrs:{id:"boolean-model"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#boolean-model"}},[a._v("#")]),a._v(" boolean model")]),a._v(" "),t("p",[a._v("先过滤出包含指定")]),a._v(" "),t("h2",{attrs:{id:"relevance-score-tf-idf算法"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#relevance-score-tf-idf算法"}},[a._v("#")]),a._v(" relevance score（TF/IDF算法）")]),a._v(" "),t("p",[a._v("再计算相关性分值，")]),a._v(" "),t("ul",[t("li",[t("p",[a._v("Term frequency （TF） : 搜索文本中的各个词条在field文本中出现了多少次，出现次数越多，就越相关 (不同词条，越多越好)")])]),a._v(" "),t("li",[t("p",[a._v("Inverse document frequency : 搜索文本中的各个词条在整个索引的所有文档中出现了多少次，出现的次数越多，就越不相关(相同词条，越少越好)")])]),a._v(" "),t("li",[t("p",[a._v("Field-length norm : field长度，field越长，相关度越弱；出现次数相同，文档长度越短越好")])])]),a._v(" "),t("h2",{attrs:{id:"空间向量模型"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#空间向量模型"}},[a._v("#")]),a._v(" 空间向量模型")]),a._v(" "),t("p",[a._v("画一个平面向量图，弧度越大，分数越底; 弧度越小，分数越高。")]),a._v(" "),t("p",[a._v("比较复杂..")])])}),[],!1,null,null,null);t.default=s.exports}}]);