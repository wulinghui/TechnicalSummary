(window.webpackJsonp=window.webpackJsonp||[]).push([[172],{532:function(a,t,r){"use strict";r.r(t);var e=r(7),s=Object(e.a)({},(function(){var a=this,t=a._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[t("h1",{attrs:{id:"kafka可视化管理工具kafka-manager"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#kafka可视化管理工具kafka-manager"}},[a._v("#")]),a._v(" "),t("a",{attrs:{href:"https://www.cnblogs.com/dadonggg/p/8205302.html",target:"_blank",rel:"noopener noreferrer"}},[a._v("Kafka可视化管理工具kafka-manager"),t("OutboundLink")],1)]),a._v(" "),t("h1",{attrs:{id:"线上环境规划"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#线上环境规划"}},[a._v("#")]),a._v(" 线上环境规划")]),a._v(" "),t("ul",[t("li",[a._v("网卡")]),a._v(" "),t("li",[a._v("硬盘，默认7日日志留存和存储的副本数")]),a._v(" "),t("li",[a._v("CPU和内存要大一点")])]),a._v(" "),t("h1",{attrs:{id:"jvm参数设置"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#jvm参数设置"}},[a._v("#")]),a._v(" JVM参数设置")]),a._v(" "),t("ul",[t("li",[a._v("用G1可以设置GC最大停顿时间")]),a._v(" "),t("li",[a._v("写数据到磁盘会用到操作系统的page cache，所以JVM内存不宜分配过大，需要给操作系统的缓存留出几个G")])]),a._v(" "),t("h1",{attrs:{id:"消息丢失问题"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#消息丢失问题"}},[a._v("#")]),a._v(" 消息丢失问题")]),a._v(" "),t("h2",{attrs:{id:"消息发送端"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#消息发送端"}},[a._v("#")]),a._v(" 消息发送端")]),a._v(" "),t("h3",{attrs:{id:"acks-0"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#acks-0"}},[a._v("#")]),a._v(" acks=0")]),a._v(" "),t("ul",[t("li",[a._v("表示producer不需要等待任何broker确认收到消息的回复，就可以继续发送下一条消息")]),a._v(" "),t("li",[a._v("性能最高，但是最容易丢消息")])]),a._v(" "),t("h3",{attrs:{id:"acks-1"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#acks-1"}},[a._v("#")]),a._v(" acks=1")]),a._v(" "),t("ul",[t("li",[a._v("至少要等待leader已经成功将数据写入本地log，但是不需要等待所有follower是否成功写入")]),a._v(" "),t("li",[a._v("如果follower没有成功备份数据，而此时leader又挂掉，则消息会丢失")])]),a._v(" "),t("h3",{attrs:{id:"acks-1或all"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#acks-1或all"}},[a._v("#")]),a._v(" acks=-1或all")]),a._v(" "),t("p",[a._v("这意味着leader需要等待所有备份(min.insync.replicas配置的备份个数)都成功写入日志，这种策略会保证只要有一个备份存活就不会丢失数据。")]),a._v(" "),t("p",[a._v("如果此时断电，producer可以知道消息没有被发送成功，将会重新发送。如果在follower收到数据以后，成功返回ack，leader断电，broker发送ack之前，数据将存在于原来的follower中(客户端重复发送，会造成数据重复)。在重新选举以后，新的leader会持有该部分数据。")]),a._v(" "),t("p",[a._v("ISR中的follower为空，还是会丢失的。")]),a._v(" "),t("h3",{attrs:{id:"总结"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#总结"}},[a._v("#")]),a._v(" 总结")]),a._v(" "),t("ul",[t("li",[a._v("客户端设置重试、ack=-1、配置kafka中的最小副本(保证ISR里面有follower)、还有做try/catch做业务容错。")]),a._v(" "),t("li",[a._v("思路:  ISR>0防止ack降级为1，其他情况利用ack和重试机制保证、最后用业务容错做支撑。")])]),a._v(" "),t("h2",{attrs:{id:"消息消费端"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#消息消费端"}},[a._v("#")]),a._v(" 消息消费端")]),a._v(" "),t("p",[a._v("如果消费这边配置的是自动提交，万一消费到数据还没处理完，就自动提交offset了，但是此时你consumer直接宕机了，未处理完的数据丢失了，下次也消费不到了。所以设置手动提交")]),a._v(" "),t("h2",{attrs:{id:"总结-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#总结-2"}},[a._v("#")]),a._v(" 总结")]),a._v(" "),t("p",[a._v("这里一般都是看场景设置ack和手动提交")]),a._v(" "),t("h1",{attrs:{id:"消息重复消费"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#消息重复消费"}},[a._v("#")]),a._v(" 消息重复消费")]),a._v(" "),t("h2",{attrs:{id:"消息发送端-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#消息发送端-2"}},[a._v("#")]),a._v(" 消息发送端")]),a._v(" "),t("p",[a._v("发送消息如果配置了重试机制，比如网络抖动时间过长导致发送端发送超时，实际broker可能已经接收到消息，但发送方会重新发送消息")]),a._v(" "),t("h2",{attrs:{id:"消息消费端-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#消息消费端-2"}},[a._v("#")]),a._v(" 消息消费端")]),a._v(" "),t("p",[a._v("如果消费这边配置的是自动提交，刚拉取了一批数据处理了一部分，但还没来得及提交，服务挂了，下次重启又会拉取相同的一批数据重复处理。")]),a._v(" "),t("ul",[t("li",[a._v("手动提交也有可能会出现上面的情况")])]),a._v(" "),t("h2",{attrs:{id:"总结-3"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#总结-3"}},[a._v("#")]),a._v(" 总结")]),a._v(" "),t("p",[a._v("一般都是消费端都是要做消费幂等处理的。")]),a._v(" "),t("h1",{attrs:{id:"消息乱序"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#消息乱序"}},[a._v("#")]),a._v(" 消息乱序")]),a._v(" "),t("h2",{attrs:{id:"消息发送端-3"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#消息发送端-3"}},[a._v("#")]),a._v(" 消息发送端")]),a._v(" "),t("ul",[t("li",[a._v("如果发送端配置了重试机制，kafka不会等之前那条消息完全发送成功才去发送下一条消息，这样可能会出现，发送了1，2，3条消息，第一条超时了，后面两条发送成功，再重试发送第1条消息，这时消息在broker端的顺序就是2，3，1了。")]),a._v(" "),t("li",[a._v("是否一定要配置重试要根据业务情况而定。也可以用同步发送的模式去发消息，当然acks不能设置为0，这样也能保证消息发送的有序。")])]),a._v(" "),t("h2",{attrs:{id:"保证全链路消息顺序消费"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#保证全链路消息顺序消费"}},[a._v("#")]),a._v(" 保证全链路消息顺序消费")]),a._v(" "),t("ul",[t("li",[a._v("从发送端开始，将所有有序消息发送到同一个分区，然后用一个消费者去消费，但是这种性能比较低。")]),a._v(" "),t("li",[a._v("或者: 消费者端接收到消息后将需要保证顺序消费的几条消费发到内存队列(可以搞多个)，一个内存队列开启一个线程顺序处理消息")])]),a._v(" "),t("h1",{attrs:{id:"消息积压"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#消息积压"}},[a._v("#")]),a._v(" 消息积压")]),a._v(" "),t("h2",{attrs:{id:"实时-消费任务挂掉导致的消费滞后"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#实时-消费任务挂掉导致的消费滞后"}},[a._v("#")]),a._v(" 实时/消费任务挂掉导致的消费滞后")]),a._v(" "),t("ul",[t("li",[t("p",[a._v("线上有时因为发送方发送消息速度过快，或者消费方处理消息过慢，可能会导致broker积压大量未消费消息")]),a._v(" "),t("blockquote",[t("p",[a._v("方案一: 此种情况如果积压了上百万未消费消息需要紧急处理，可以修改消费端程序，让其将收到的消息快速转发到其他topic(可以设置很多分区)，然后再启动多个消费者同时消费新主题的不同分区。")])]),a._v(" "),t("blockquote",[t("p",[a._v("方案二:  临时扩容新节点，但是小心触发重平衡，导致消费者不消费。")])])])]),a._v(" "),t("h2",{attrs:{id:"kafka分区少了"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#kafka分区少了"}},[a._v("#")]),a._v(" Kafka分区少了")]),a._v(" "),t("p",[a._v("如果数据量很大，合理的增加Kafka分区数是关键。但是小心触发重平衡，导致消费者不消费。")]),a._v(" "),t("h2",{attrs:{id:"由于kafka消息key设置的不合理-导致分区数据不均衡"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#由于kafka消息key设置的不合理-导致分区数据不均衡"}},[a._v("#")]),a._v(" 由于Kafka消息key设置的不合理，导致分区数据不均衡")]),a._v(" "),t("p",[a._v("可以在Kafka producer处，给key加随机后缀，使其均衡。")]),a._v(" "),t("h2",{attrs:{id:"程序有bug-数据问题"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#程序有bug-数据问题"}},[a._v("#")]),a._v(" 程序有bug/数据问题")]),a._v(" "),t("ul",[t("li",[a._v("由于消息数据格式变动或消费者程序有bug，导致消费者一直消费不成功，也可能导致broker积压大量未消费消息。")])]),a._v(" "),t("blockquote",[t("p",[a._v("此种情况可以将这些消费不成功的消息转发到其它队列里去(类似死信队列)，后面再慢慢分析死信队列里的消息处理问题。")])]),a._v(" "),t("h1",{attrs:{id:"延时队列的实现"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#延时队列的实现"}},[a._v("#")]),a._v(" 延时队列的实现")]),a._v(" "),t("h2",{attrs:{id:"延时队列存储的对象是延时消息。"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#延时队列存储的对象是延时消息。"}},[a._v("#")]),a._v(" 延时队列存储的对象是延时消息。")]),a._v(" "),t("ul",[t("li",[a._v("订单完成1小时后通知用户进行评价。")]),a._v(" "),t("li",[a._v("30 分钟后未支付，取消订单")])]),a._v(" "),t("h2",{attrs:{id:"实现思路"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#实现思路"}},[a._v("#")]),a._v(" 实现思路")]),a._v(" "),t("ul",[t("li",[a._v("发送延时消息时先把消息按照不同的延迟时间段发送到指定的队列中（topic_1s，topic_5s，topic_10s，...topic_2h，这个一般不能支持任意时间段的延时）")]),a._v(" "),t("li",[a._v("然后通过定时器进行轮训消费这些topic，查看消息是否到期，如果到期就把这个消息发送到具体业务处理的topic中，队列中消息越靠前的到期时间越早，具体来说就是定时器在一次消费过程中，对消息的发送时间做判断，看下是否延迟到对应时间了，如果到了就转发，如果还没到这一次定时任务就可以提前结束了，并把偏移量seek到上一次消费的位置以便等待下一个周期再次消费这条消息。")]),a._v(" "),t("li",[a._v("一个消费者对应一个分区，而一个分区是局部有序的，所以也不用考虑，分区的顺序问题，但是如果重试机制导致的顺序，这里会导致业务部分的延迟，但是延迟可接受。")]),a._v(" "),t("li",[a._v("这里需要注意spring-boot，多线程多消费者，的定时器编写。")])]),a._v(" "),t("h1",{attrs:{id:"消息回溯"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#消息回溯"}},[a._v("#")]),a._v(" 消息回溯")]),a._v(" "),t("p",[a._v("可以用consumer的offsetsForTimes、seek等方法指定从某个offset偏移的消息开始消费")]),a._v(" "),t("h1",{attrs:{id:"分区数越多吞吐量越高吗"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#分区数越多吞吐量越高吗"}},[a._v("#")]),a._v(" 分区数越多吞吐量越高吗")]),a._v(" "),t("p",[a._v('如果分区数设置过大，比如设置10000，可能会设置不成功，后台会报错"java.io.IOException : Too many open files"')]),a._v(" "),t("blockquote",[t("p",[a._v("这是linux下用ulimit设置打开文件的数量，默认是1024")]),a._v(" "),t("p",[t("code",[a._v("ulimit -n 65535")])])]),a._v(" "),t("h1",{attrs:{id:"消息传递保障"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#消息传递保障"}},[a._v("#")]),a._v(" 消息传递保障")]),a._v(" "),t("h2",{attrs:{id:"at-most-once"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#at-most-once"}},[a._v("#")]),a._v(" at most once")]),a._v(" "),t("ul",[t("li",[a._v("消费者最多收到一次消息，0--1次")]),a._v(" "),t("li",[a._v("acks = 0")])]),a._v(" "),t("h2",{attrs:{id:"at-least-once"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#at-least-once"}},[a._v("#")]),a._v(" at least once")]),a._v(" "),t("ul",[t("li",[a._v("消费者至少收到一次消息，1--多次")]),a._v(" "),t("li",[a._v("ack = all 可以实现")])]),a._v(" "),t("h2",{attrs:{id:"exactly-once"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#exactly-once"}},[a._v("#")]),a._v(" exactly once")]),a._v(" "),t("ul",[t("li",[a._v("消费者刚好收到一次消息")]),a._v(" "),t("li",[a._v("at least once 加上消费者幂等性可以实现")])]),a._v(" "),t("h1",{attrs:{id:"kafka生产者的幂等性"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#kafka生产者的幂等性"}},[a._v("#")]),a._v(" kafka生产者的幂等性")]),a._v(" "),t("ul",[t("li",[a._v("只需在生产者加上参数 props.put(“enable.idempotence”, true)")])]),a._v(" "),t("h2",{attrs:{id:"实现原理"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#实现原理"}},[a._v("#")]),a._v(" 实现原理")]),a._v(" "),t("p",[a._v("kafka每次发送消息会生成PID和Sequence Number，并将这两个属性一起发送给broker，broker会将PID和Sequence Number跟消息绑定一起存起来，下次如果生产者重发相同消息，broker会检查PID和Sequence Number，如果相同不会再接收。")]),a._v(" "),t("h1",{attrs:{id:"kafka消费者的幂等性"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#kafka消费者的幂等性"}},[a._v("#")]),a._v(" kafka消费者的幂等性")]),a._v(" "),t("p",[a._v("见RabbitMQ的章节.")]),a._v(" "),t("h1",{attrs:{id:"kafka的事务"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#kafka的事务"}},[a._v("#")]),a._v(" kafka的事务")]),a._v(" "),t("ul",[t("li",[a._v("Kafka的事务主要是保障一次发送多条消息的事务一致性(要么同时成功要么同时失败)")]),a._v(" "),t("li",[a._v("不同于Rocketmq，Rocketmq是保障本地事务(比如数据库)与mq消息发送的事务一致性")])]),a._v(" "),t("h1",{attrs:{id:"kafka高性能的原因"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#kafka高性能的原因"}},[a._v("#")]),a._v(" kafka高性能的原因")]),a._v(" "),t("ul",[t("li",[a._v("磁盘顺序读写：kafka消息不能修改以及不会从文件中间删除保证了磁盘顺序读，kafka的消息写入文件都是追加在文件末尾，不会写入文件中的某个位置(随机写)保证了磁盘顺序写")]),a._v(" "),t("li",[a._v("数据传输的零拷贝")]),a._v(" "),t("li",[a._v("读写数据的批量batch处理以及压缩传输")])]),a._v(" "),t("h1",{attrs:{id:"参考资料"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#参考资料"}},[a._v("#")]),a._v(" 参考资料")]),a._v(" "),t("p",[t("a",{attrs:{href:"https://zhuanlan.zhihu.com/p/312089762",target:"_blank",rel:"noopener noreferrer"}},[a._v("Kafka集群消息积压问题及处理策略"),t("OutboundLink")],1)]),a._v(" "),t("p",[t("a",{attrs:{href:"https://zhuanlan.zhihu.com/p/365802989",target:"_blank",rel:"noopener noreferrer"}},[a._v("基于kafka实现延迟队列"),t("OutboundLink")],1)]),a._v(" "),t("p",[t("a",{attrs:{href:"https://blog.csdn.net/sinat_36553913/article/details/102641986",target:"_blank",rel:"noopener noreferrer"}},[a._v("Kafka学习(一)：消费者实现对分区的并发消费"),t("OutboundLink")],1)]),a._v(" "),t("blockquote",[t("p",[a._v("在spring中实现消息的并发消费采用的是线程封闭的策略，具体实现是在创建监听器容器时，会根据配置的concurrency来创建多个KafkaMessageListenerContainer，在该类中又有内部类ListenerConsumer，在该内部类中封闭创建了consumer对象。以此来实现主题消息的并发消费。也就是多线程多消费者。")])]),a._v(" "),t("p",[t("a",{attrs:{href:"https://z.itpub.net/article/detail/77548FB375E19D324158156B0F7D403E",target:"_blank",rel:"noopener noreferrer"}},[a._v("因为一次 Kafka 宕机，我明白了 Kafka 高可用原理！"),t("OutboundLink")],1)]),a._v(" "),t("blockquote",[t("p",[t("code",[a._v("Asks=All")]),a._v(" 就不会出现丢失消息的情况吗？答案是否。当ISR列表只剩Leader的情况下， "),t("code",[a._v("Asks=All")]),a._v(" 相当于 "),t("code",[a._v("Asks=1")]),a._v(" ，这种情况下如果节点宕机了，还能保证数据不丢失吗？因此只有在 "),t("code",[a._v("Asks=All")]),a._v("并且有ISR中有两个副本的情况下才能保证数据不丢失。")]),a._v(" "),t("p",[a._v("设置 "),t("code",[a._v("replication-factor")]),a._v(" 副本数为3。  \t通过设置最少的ISR，可以解决这个问题。")])]),a._v(" "),t("p",[t("a",{attrs:{href:"https://blog.csdn.net/qq_37865420/article/details/106852433",target:"_blank",rel:"noopener noreferrer"}},[a._v("解决kafka ISR缺失严重导致消费异常的方法"),t("OutboundLink")],1)]),a._v(" "),t("blockquote",[t("p",[a._v("对应无法消费的业务topic存在部分分区的ISR列表丢失2/3，且随着时间的推移，isr缺失的分区占比在增加。")]),a._v(" "),t("p",[a._v("导致无法消费kafka，且往kafka写消息报错\n"),t("a",{attrs:{href:"https://blog.csdn.net/qq_37865420/article/details/106711362",target:"_blank",rel:"noopener noreferrer"}},[a._v("调整这些参数"),t("OutboundLink")],1),a._v(":   replica..... 的配置，如 响应leader的最长等待时间、落后消息数量、socket超时时间、socket缓存大小、每次获取数据的最大字节数、通信之间的最大等待时间、复制的线程数、将最高水位进行flush的时间间隔等等")])]),a._v(" "),t("p",[t("a",{attrs:{href:"https://zhuanlan.zhihu.com/p/354772550",target:"_blank",rel:"noopener noreferrer"}},[a._v("Kafka 会不会丢消息？怎么处理的?"),t("OutboundLink")],1)]),a._v(" "),t("p",[t("a",{attrs:{href:"https://www.jianshu.com/p/a2f21abec785",target:"_blank",rel:"noopener noreferrer"}},[a._v("Kafka——一致性重要机制之ISR(kafka replica)"),t("OutboundLink")],1)]),a._v(" "),t("div",{staticClass:"language-bash line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-bash"}},[t("code",[t("span",{pre:!0,attrs:{class:"token assign-left variable"}},[a._v("min.insync.replicas")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# 需要保证ISR中至少有多少个replica")]),a._v("\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br")])])])}),[],!1,null,null,null);t.default=s.exports}}]);