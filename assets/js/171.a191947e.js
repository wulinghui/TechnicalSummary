(window.webpackJsonp=window.webpackJsonp||[]).push([[171],{531:function(a,r,e){"use strict";e.r(r);var t=e(7),s=Object(t.a)({},(function(){var a=this,r=a._self._c;return r("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[r("h1",{attrs:{id:"核心总控制器controller"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#核心总控制器controller"}},[a._v("#")]),a._v(" 核心总控制器Controller")]),a._v(" "),r("ul",[r("li",[a._v("Kafka集群中会有一个或者多个broker，其中有一个broker会被选举为控制器（Kafka Controller），它负责管理整个集群中所有分区和副本的状态。")]),a._v(" "),r("li",[a._v("当某个分区的leader副本出现故障时，由控制器负责为该分区选举新的leader副本")]),a._v(" "),r("li",[a._v("当检测到某个分区的ISR集合发生变化时，由控制器负责通知所有broker更新其元数据信息。")]),a._v(" "),r("li",[a._v("当使用kafka-topics.sh脚本为某个topic增加分区数量时，同样还是由控制器负责让新分区被其他节点感知到。")])]),a._v(" "),r("h1",{attrs:{id:"controller选举机制"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#controller选举机制"}},[a._v("#")]),a._v(" Controller选举机制")]),a._v(" "),r("ul",[r("li",[a._v("集群中每个broker都会尝试在zookeeper上创建一个 /controller 临时节点，zookeeper会保证有且仅有一个broker能创建成功。")]),a._v(" "),r("li",[a._v("当这个controller角色的broker宕机了，此时zookeeper临时节点会消失，集群里其他broker会一直监听这个临时节点，发现临时节点消失了，就竞争再次创建临时节点。")])]),a._v(" "),r("h1",{attrs:{id:"controller职责"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#controller职责"}},[a._v("#")]),a._v(" Controller职责")]),a._v(" "),r("ul",[r("li",[a._v("监听broker相关的变化。")]),a._v(" "),r("li",[a._v("监听topic相关的变化")]),a._v(" "),r("li",[a._v("从Zookeeper中读取获取当前所有与topic、partition以及broker有关的信息并进行相应的管理")]),a._v(" "),r("li",[a._v("更新集群的元数据信息，同步到其他普通的broker节点中")])]),a._v(" "),r("h1",{attrs:{id:"partition副本选举leader机制"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#partition副本选举leader机制"}},[a._v("#")]),a._v(" Partition副本选举Leader机制")]),a._v(" "),r("ul",[r("li",[a._v("controller感知到分区leader所在的broker挂了，controller会从ISR列表里挑第一个broker作为leader(第一个broker最先放进ISR列表，可能是同步数据最多的副本)")])]),a._v(" "),r("h2",{attrs:{id:"副本进入isr列表条件"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#副本进入isr列表条件"}},[a._v("#")]),a._v(" 副本进入ISR列表条件")]),a._v(" "),r("ul",[r("li",[a._v("副本节点不能产生分区，必须能与zookeeper保持会话以及跟leader副本网络连通")]),a._v(" "),r("li",[a._v("副本能复制leader上的所有写操作，并且不能落后太多(与leader副本同步滞后的副本，是由 replica.lag.time.max.ms 配置决定的，超过这个时间都没有跟leader同步过的一次的副本会被移出ISR列表)")])]),a._v(" "),r("h1",{attrs:{id:"消费者消费消息的offset记录机制"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#消费者消费消息的offset记录机制"}},[a._v("#")]),a._v(" 消费者消费消息的offset记录机制")]),a._v(" "),r("p",[a._v("每个consumer会定期将自己消费分区的offset提交给kafka内部topic：__consumer_offsets，提交过去的时候，key是consumerGroupId+topic+分区号，value就是当前offset的值。")]),a._v(" "),r("h1",{attrs:{id:"消费者rebalance机制"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#消费者rebalance机制"}},[a._v("#")]),a._v(" 消费者Rebalance机制")]),a._v(" "),r("h2",{attrs:{id:"定义"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#定义"}},[a._v("#")]),a._v(" 定义")]),a._v(" "),r("ul",[r("li",[a._v("rebalance就是说如果消费组里的消费者数量有变化或消费的分区数有变化，kafka会重新分配消费者消费分区的关系。")])]),a._v(" "),r("h2",{attrs:{id:"触发情况"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#触发情况"}},[a._v("#")]),a._v(" 触发情况")]),a._v(" "),r("ul",[r("li",[a._v("消费组里的consumer增加或减少了")]),a._v(" "),r("li",[a._v("动态给topic增加了分区")]),a._v(" "),r("li",[a._v("消费组订阅了更多的topic")])]),a._v(" "),r("h2",{attrs:{id:"产生问题"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#产生问题"}},[a._v("#")]),a._v(" 产生问题")]),a._v(" "),r("p",[a._v("rebalance过程中，消费者无法从kafka消费消息，对kafka的TPS有影响")]),a._v(" "),r("h2",{attrs:{id:"注意"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#注意"}},[a._v("#")]),a._v(" 注意")]),a._v(" "),r("p",[a._v("rebalance只针对subscribe这种不指定分区消费的情况，如果通过assign这种消费方式指定了分区，kafka不会进行rebanlance。")]),a._v(" "),r("p",[a._v("但是assign指定分区，他是效率不高的。")]),a._v(" "),r("h1",{attrs:{id:"消费者rebalance分区分配策略"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#消费者rebalance分区分配策略"}},[a._v("#")]),a._v(" 消费者Rebalance分区分配策略")]),a._v(" "),r("h2",{attrs:{id:"range策略"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#range策略"}},[a._v("#")]),a._v(" range策略")]),a._v(" "),r("p",[a._v("按照分区序号排序")]),a._v(" "),r("h2",{attrs:{id:"round-robin策略"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#round-robin策略"}},[a._v("#")]),a._v(" round-robin策略")]),a._v(" "),r("p",[a._v("轮询分配")]),a._v(" "),r("h2",{attrs:{id:"sticky策略"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#sticky策略"}},[a._v("#")]),a._v(" sticky策略")]),a._v(" "),r("p",[a._v("初始时分配策略与round-robin类似，但是在rebalance的时候，需要保证如下两个原则:1）分区的分配要尽可能均匀 。2）分区的分配尽可能与上次分配的保持相同。")]),a._v(" "),r("h1",{attrs:{id:"rebalance过程"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#rebalance过程"}},[a._v("#")]),a._v(" Rebalance过程")]),a._v(" "),r("ol",[r("li",[a._v("选择组协调器")]),a._v(" "),r("li",[a._v("加入消费组JOIN GROUP")]),a._v(" "),r("li",[a._v("SYNC GROUP")])]),a._v(" "),r("h1",{attrs:{id:"producer发布消息机制剖析"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#producer发布消息机制剖析"}},[a._v("#")]),a._v(" producer发布消息机制剖析")]),a._v(" "),r("h2",{attrs:{id:"写入方式"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#写入方式"}},[a._v("#")]),a._v(" 写入方式")]),a._v(" "),r("p",[a._v("采用 push 模式将消息发布到 broker，每条消息都被 append 到 patition 中，属于顺序写磁盘（顺序写磁盘效率比随机写内存要高，保障 kafka 吞吐率）")]),a._v(" "),r("h2",{attrs:{id:"消息路由"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#消息路由"}},[a._v("#")]),a._v(" 消息路由")]),a._v(" "),r("p",[a._v("producer 发送消息到 broker 时，会根据分区算法选择将其存储到哪一个 partition。")]),a._v(" "),r("p",[a._v("其路由机制为:")]),a._v(" "),r("ol",[r("li",[a._v("指定了 patition，则直接使用；")]),a._v(" "),r("li",[a._v("未指定 patition 但指定 key，通过对 key 的 value 进行hash 选出一个 patition")]),a._v(" "),r("li",[a._v("patition 和 key 都未指定，使用轮询选出一个 patition。")])]),a._v(" "),r("h1",{attrs:{id:"日志分段存储"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#日志分段存储"}},[a._v("#")]),a._v(" 日志分段存储")]),a._v(" "),r("ul",[r("li",[a._v("一个分区的消息数据对应存储在一个文件夹下，以topic名称+分区号命名，消息在分区内是分段(segment)存储，每个段的消息都存储在不一样的log文件里，这种特性方便old segment file快速被删除，kafka规定了一个段位的 log 文件最大为 1G，做这个限制目的是为了方便把 log 文件加载到内存去操作")]),a._v(" "),r("li",[a._v("一个日志段文件满了，就自动开一个新的日志段文件来写入，避免单个文件过大，影响文件的读写性能，这个过程叫做 log rolling，正在被写入的那个日志段文件，叫做 active log segment。")])]),a._v(" "),r("h1",{attrs:{id:"kafka-zookeeper-节点"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#kafka-zookeeper-节点"}},[a._v("#")]),a._v(" "),r("a",{attrs:{href:"https://blog.csdn.net/lkforce/article/details/77864472",target:"_blank",rel:"noopener noreferrer"}},[a._v("kafka zookeeper 节点"),r("OutboundLink")],1)]),a._v(" "),r("p",[r("img",{attrs:{src:"https://img-blog.csdn.net/20170906113741757",alt:""}})])])}),[],!1,null,null,null);r.default=s.exports}}]);