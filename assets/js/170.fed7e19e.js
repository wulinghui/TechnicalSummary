(window.webpackJsonp=window.webpackJsonp||[]).push([[170],{528:function(a,r,t){"use strict";t.r(r);var e=t(7),s=Object(e.a)({},(function(){var a=this,r=a._self._c;return r("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[r("h1",{attrs:{id:"使用场景"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#使用场景"}},[a._v("#")]),a._v(" 使用场景")]),a._v(" "),r("h2",{attrs:{id:"日志收集"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#日志收集"}},[a._v("#")]),a._v(" 日志收集")]),a._v(" "),r("p",[a._v("通过kafka以统一接口服务的方式开放给各种consumer")]),a._v(" "),r("h2",{attrs:{id:"消息系统"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#消息系统"}},[a._v("#")]),a._v(" 消息系统")]),a._v(" "),r("p",[a._v("解耦和生产者和消费者、缓存消息等")]),a._v(" "),r("h2",{attrs:{id:"用户活动跟踪"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#用户活动跟踪"}},[a._v("#")]),a._v(" 用户活动跟踪")]),a._v(" "),r("p",[a._v("Kafka经常被用来记录web用户或者app用户的各种活动")]),a._v(" "),r("h2",{attrs:{id:"运营指标"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#运营指标"}},[a._v("#")]),a._v(" 运营指标")]),a._v(" "),r("p",[a._v("Kafka也经常用来记录运营监控数据")]),a._v(" "),r("h1",{attrs:{id:"基本概念"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#基本概念"}},[a._v("#")]),a._v(" 基本概念")]),a._v(" "),r("ul",[r("li",[a._v("一个分布式的，分区的消息(官方称之为commit log)服务")]),a._v(" "),r("li",[a._v("Kafka借鉴了JMS规范的思想，但是确并没有完全遵循JMS规范。")]),a._v(" "),r("li",[a._v("服务端(brokers)和客户端(producer、consumer)之间通信通过TCP协议来完成。")])]),a._v(" "),r("h1",{attrs:{id:"相关术语"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#相关术语"}},[a._v("#")]),a._v(" 相关术语")]),a._v(" "),r("h2",{attrs:{id:"message"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#message"}},[a._v("#")]),a._v(" message")]),a._v(" "),r("p",[a._v("基础的消息(Message)，生产消费的基本单位。")]),a._v(" "),r("h2",{attrs:{id:"broker"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#broker"}},[a._v("#")]),a._v(" Broker")]),a._v(" "),r("p",[a._v("消息中间件处理节点，一个Kafka节点就是一个broker，一个或者多个Broker可以组成一个Kafka集群")]),a._v(" "),r("h2",{attrs:{id:"topic"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#topic"}},[a._v("#")]),a._v(" Topic")]),a._v(" "),r("p",[a._v("Kafka根据topic对消息进行归类，发布到Kafka集群的每条消息都需要指定一个topic")]),a._v(" "),r("h2",{attrs:{id:"producer-生产者"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#producer-生产者"}},[a._v("#")]),a._v(" Producer（生产者）")]),a._v(" "),r("p",[a._v("消息生产者，向Broker发送消息的客户端")]),a._v(" "),r("h2",{attrs:{id:"consumer-消费者"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#consumer-消费者"}},[a._v("#")]),a._v(" Consumer（消费者）")]),a._v(" "),r("p",[a._v("消息消费者，从Broker读取消息的客户端")]),a._v(" "),r("h2",{attrs:{id:"consumergroup"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#consumergroup"}},[a._v("#")]),a._v(" ConsumerGroup")]),a._v(" "),r("p",[a._v("每个Consumer属于一个特定的Consumer Group，一条消息可以被多个不同的Consumer Group消费，但是一个Consumer Group中只能有一个Consumer能够消费该消息")]),a._v(" "),r("h2",{attrs:{id:"partition-分区"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#partition-分区"}},[a._v("#")]),a._v(" Partition（分区）")]),a._v(" "),r("ul",[r("li",[a._v("物理上的概念，一个topic可以分为多个partition，每个partition内部消息是有序的")]),a._v(" "),r("li",[a._v("逻辑上topic的下一级，kafka为了提高吞吐量和可用性，会把一类消息分成多个区存储。")]),a._v(" "),r("li",[a._v("topic中的数据分割为一个或多个partition。每个topic至少有一个partition。每个partition中的数据使用多个segment文件存储。同一个partition中的数据是有序的，不同partition间的数据丢失了数据的顺序。如果topic有多个partition，消费数据时就不能保证数据的顺序。在需要严格保证消息的消费顺序的场景下，需要将partition数目设为1。")])]),a._v(" "),r("h2",{attrs:{id:"replica-副本"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#replica-副本"}},[a._v("#")]),a._v(" replica （副本）")]),a._v(" "),r("ul",[r("li",[a._v("kafka为了实现高可用，会对partition（分区）保存多个replica（副本），存在的唯一理由就是为了实现消息的高可靠存储，不让消息丢失。")]),a._v(" "),r("li",[a._v("其中又分leader 副本和follower副本，follower同步leader副本，leader副本宕机时，从剩余follower副本中选出一个作为新的leader 副本，实现高可用（一个partition的多个副本一定不会在同一个broker上）。")])]),a._v(" "),r("h2",{attrs:{id:"leader"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#leader"}},[a._v("#")]),a._v(" Leader")]),a._v(" "),r("ul",[r("li",[a._v("每个partition有多个副本，其中有且仅有一个作为Leader，Leader是当前负责数据的读写的partition。")]),a._v(" "),r("li",[a._v("Leader和Follower都是针对Partition，来说的。")])]),a._v(" "),r("h2",{attrs:{id:"follower"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#follower"}},[a._v("#")]),a._v(" Follower")]),a._v(" "),r("p",[a._v("Follower跟随Leader，所有写请求都通过Leader路由，数据变更会广播给所有Follower，Follower与Leader保持数据同步。如果Leader失效，则从Follower中选举出一个新的Leader。当Follower与Leader挂掉、卡住或者同步太慢，leader会把这个follower从“in sync replicas”（ISR）列表中删除，重新创建一个Follower。")]),a._v(" "),r("h2",{attrs:{id:"offset"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#offset"}},[a._v("#")]),a._v(" Offset")]),a._v(" "),r("p",[a._v("消息位移值一共有两种:")]),a._v(" "),r("ul",[r("li",[a._v("第一种是分区内的每条消息都有一个位移值，代表每条消息在文件中的位置,offset从0到消息数量-1，就好比数组的下标。")]),a._v(" "),r("li",[a._v("第二种相对于kafka消费端而言的offset，代表了消费端当前的读取进度，比如消费端offset为3，代表消费者已经消费到了第四条消息。")])]),a._v(" "),r("p",[a._v("kafka的存储文件都是按照offset.kafka来命名，用offset做名字的好处是方便查找。例如你想找位于2049的位置，只要找到2048.kafka的文件即可。当然the first offset就是00000000000.kafka")]),a._v(" "),r("h2",{attrs:{id:"isr-in-sync-replica-与leader-replica保持同步的replica集合"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#isr-in-sync-replica-与leader-replica保持同步的replica集合"}},[a._v("#")]),a._v(" ISR (in-sync replica，与leader replica保持同步的replica集合)")]),a._v(" "),r("p",[a._v("kafka会为每一个partition动态维护一个replica集合，该集合中的replica存储的所有消息日志与leader replica保持同步状态，如果因为网络延迟等原因部分ISR中的replica消息同步进度落后leader replica太多，则会将该replica踢出ISR，等后续追上进度时kafka再将其自动加入ISR。")]),a._v(" "),r("h1",{attrs:{id:"kafka基本使用"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#kafka基本使用"}},[a._v("#")]),a._v(" "),r("a",{attrs:{href:"https://www.cnblogs.com/javabg/p/9592193.html",target:"_blank",rel:"noopener noreferrer"}},[a._v("kafka基本使用"),r("OutboundLink")],1)]),a._v(" "),r("ul",[r("li",[a._v("安装")]),a._v(" "),r("li",[a._v("发消息")]),a._v(" "),r("li",[a._v("消费消息")])]),a._v(" "),r("h1",{attrs:{id:"主题topic和消息日志log"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#主题topic和消息日志log"}},[a._v("#")]),a._v(" 主题Topic和消息日志Log")]),a._v(" "),r("ul",[r("li",[a._v("可以理解Topic是一个类别的名称，同类消息发送到同一个Topic下面。对于每一个Topic，下面可以有多个分区(Partition)日志文件")]),a._v(" "),r("li",[a._v("Partition是一个有序的message序列，每个partition，都对应一个commit log文件。一个partition中的message的offset都是唯一的，但是不同的partition中的message的offset可能是相同的")]),a._v(" "),r("li",[a._v("kafka一般不会删除消息，不管这些消息有没有被消费。只会根据配置的日志保留时间，默认保留最近一周的日志消息。kafka的性能与保留的消息数据量大小没有关系，因此保存大量的数据消息日志信息不会有什么影响。")]),a._v(" "),r("li",[a._v("每个consumer是基于自己在commit log中的消费进度(offset)来进行工作的。这意味kafka中的consumer对集群的影响是非常小的，这也是性能高。")])]),a._v(" "),r("h1",{attrs:{id:"理解topic-partition和broker"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#理解topic-partition和broker"}},[a._v("#")]),a._v(" 理解Topic，Partition和Broker")]),a._v(" "),r("ul",[r("li",[a._v("一个topic，代表逻辑上的一个业务数据集")]),a._v(" "),r("li",[a._v("如果把这么多数据都放在一台机器上可定会有容量限制问题，那么就可以在topic内部划分多个partition来分片存储数据，不同的partition可以位于不同的机器上，每台机器上都运行一个Kafka的进程Broker。partition在不同的broker中都可以为leader")])]),a._v(" "),r("h1",{attrs:{id:"为什么要对topic下数据进行分区存储"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#为什么要对topic下数据进行分区存储"}},[a._v("#")]),a._v(" 为什么要对Topic下数据进行分区存储")]),a._v(" "),r("ul",[r("li",[a._v("commit log文件会受到所在机器的文件系统大小的限制")]),a._v(" "),r("li",[a._v("为了提高并行度")])]),a._v(" "),r("h1",{attrs:{id:"集群"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#集群"}},[a._v("#")]),a._v(" 集群")]),a._v(" "),r("ul",[r("li",[a._v("broker.id属性在kafka集群中必须要是唯一,对应连接的zookeeper必须相同")]),a._v(" "),r("li",[a._v("kafka将很多集群关键信息记录在zookeeper里，保证自己的无状态，从而在水平扩容时非常方便。")])]),a._v(" "),r("h1",{attrs:{id:"集群消费"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#集群消费"}},[a._v("#")]),a._v(" 集群消费")]),a._v(" "),r("h2",{attrs:{id:"流程"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#流程"}},[a._v("#")]),a._v(" 流程")]),a._v(" "),r("ul",[r("li",[a._v("leader处理所有的针对这个partition的读写请求，而followers被动复制leader的结果，不提供读写(主要是为了保证多副本数据与消费的一致性)。如果这个leader失效了，其中的一个follower将会自动的变成新的leader。")]),a._v(" "),r("li",[a._v("生产者将消息发送到topic中去，同时负责选择将message发送到topic的哪一个partition中。")])]),a._v(" "),r("h2",{attrs:{id:"consumers传统的消息传递模式"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#consumers传统的消息传递模式"}},[a._v("#")]),a._v(" Consumers传统的消息传递模式")]),a._v(" "),r("ul",[r("li",[a._v("queue模式：多个consumer从服务器中读取数据，消息只会到达一个consumer。所有的consumer都位于同一个consumer group 下。")]),a._v(" "),r("li",[a._v("publish-subscribe模式：消息会被广播给所有的consumer。所有的consumer都有着自己唯一的consumer group。")])]),a._v(" "),r("h2",{attrs:{id:"消费顺序问题"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#消费顺序问题"}},[a._v("#")]),a._v(" 消费顺序问题")]),a._v(" "),r("ul",[r("li",[a._v("一个partition同一个时刻在一个consumer group中只能有一个consumer instance在消费，从而保证消费顺序。")]),a._v(" "),r("li",[a._v("consumer group中的consumer instance的数量不能比一个Topic中的partition的数量多，否则，多出来的consumer消费不到消息。")]),a._v(" "),r("li",[a._v("Kafka只在partition的范围内保证消息消费的局部顺序性，不能在同一个topic中的多个partition中保证总的消费顺序性。如果有在总体上保证消费顺序的需求，那么我们可以通过将topic的partition数量设置为1，将consumer group中的consumer instance数量也设置为1，但是这样会影响性能，所以kafka的顺序消费很少用。")])]),a._v(" "),r("h1",{attrs:{id:"java代码"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#java代码"}},[a._v("#")]),a._v(" java代码")]),a._v(" "),r("ul",[r("li",[r("a",{attrs:{href:"https://blog.csdn.net/qq_44538738/article/details/114596974",target:"_blank",rel:"noopener noreferrer"}},[a._v("Java客户端访问Kafka"),r("OutboundLink")],1)]),a._v(" "),r("li",[r("a",{attrs:{href:"https://blog.csdn.net/qq_43631716/article/details/120024681",target:"_blank",rel:"noopener noreferrer"}},[a._v("Spring Boot整合Kafka"),r("OutboundLink")],1)])]),a._v(" "),r("h1",{attrs:{id:"参考资料"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#参考资料"}},[a._v("#")]),a._v(" 参考资料")]),a._v(" "),r("p",[r("a",{attrs:{href:"https://www.cnblogs.com/powerjiajun/p/11470439.html",target:"_blank",rel:"noopener noreferrer"}},[a._v("kafka架构、基本术语、消息存储结构 "),r("OutboundLink")],1)]),a._v(" "),r("p",[r("img",{attrs:{src:"https://upload-images.jianshu.io/upload_images/6084749-9beac657b22e82c0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240",alt:""}})]),a._v(" "),r("p",[r("a",{attrs:{href:"https://www.cnblogs.com/frankdeng/p/9310684.html",target:"_blank",rel:"noopener noreferrer"}},[a._v("Kafka（一）Kafka的简介与架构"),r("OutboundLink")],1)]),a._v(" "),r("p",[r("img",{attrs:{src:"https://images2018.cnblogs.com/blog/1385722/201808/1385722-20180804221732434-2116774825.png",alt:""}})])])}),[],!1,null,null,null);r.default=s.exports}}]);